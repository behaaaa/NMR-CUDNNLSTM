# -*- coding: utf-8 -*-
"""CBW.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1480KMvUrrZAgjQ3-kF3fGJJbNiUS-ayW
"""

import pandas as pd
import numpy as np
import keras
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
from keras.preprocessing.sequence import TimeseriesGenerator
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import CuDNNLSTM ,LSTM
from keras.layers import  Dropout
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import f_regression
from sklearn.feature_selection import mutual_info_regression
from keras import optimizers
from keras import activations
from keras.backend import dropout

perdf = pd.read_excel('/content/FINAL_DATA.xlsx','WELL_A') # read data
perdf= perdf.iloc[:,1:]
y_col='CBW' # define y variable, i.e., what we want to predict
print(perdf.shape) # print the number of rows anc columns
perdf= perdf.iloc[:,:8]# BVi
perdf.head()

u =6
u1 = SelectKBest(score_func = f_classif , k = u)
fcalssif = u1.fit(perdf.iloc[:,:7], perdf.iloc[:,7:8])
p1= perdf.iloc[:,:7].columns[fcalssif.get_support(indices=True)].tolist()



u2 = SelectKBest(score_func = f_regression , k = u)
freg = u2.fit(perdf.iloc[:,:7], perdf.iloc[:,7:8])
p2=perdf.iloc[:,:7].columns[freg.get_support(indices=True)].tolist()



u3 = SelectKBest(score_func = mutual_info_regression , k = u)
mutual = u3.fit(perdf.iloc[:,:7], perdf.iloc[:,7:8])
p3=perdf.iloc[:,:7].columns[mutual.get_support(indices=True)].tolist()

print("f_classif = p1")
print(p1)
print("f_regression = p2")
print(p2)
print("mutual_info_regression = p3")
print(p3)

df = pd.DataFrame()
for i in p1:
  df[i] = perdf[i]
df[y_col] = perdf[y_col]
print(df)

plt.figure(figsize=(50,4))
plt.plot(range(len(df)),df[y_col]);

test_size = int(len(df) * 0.3) # the test data will be 30% (0.3) of the entire data
train = df.iloc[:-test_size,:].copy()
# the copy() here is important, it will prevent us from getting: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_index,col_indexer] = value instead
test = df.iloc[-test_size:,:].copy()
print(train.shape, test.shape)

plt.figure(figsize=(50,4))
plt.plot(train.index,train[y_col],label='Train');
plt.plot(test.index,test[y_col],label='test')
plt.legend();

#separate X and y only for the train data (for now)
X_train = train.drop(y_col,axis=1).copy()
y_train = train[[y_col]].copy() # the double brakets here are to keep the y in a dataframe format, otherwise it will be pandas Series
print(X_train.shape, y_train.shape)

Xscaler = MinMaxScaler(feature_range=(0, 1)) # scale so that all the X data will range from 0 to 1
Xscaler.fit(X_train)
scaled_X_train = Xscaler.transform(X_train)
print(X_train.shape)
Yscaler = MinMaxScaler(feature_range=(0, 1))
Yscaler.fit(y_train)
scaled_y_train = Yscaler.transform(y_train)
print(scaled_y_train.shape)
scaled_y_train = scaled_y_train.reshape(-1) # remove the second dimention from y so the shape changes from (n,1) to (n,)
print(scaled_y_train.shape)

scaled_y_train = np.insert(scaled_y_train, 0, 0)
scaled_y_train = np.delete(scaled_y_train, -1)

n_input = 100 #how many samples/rows/timesteps to look in the past in order to forecast the next sample # 10 good
n_features= X_train.shape[1] # how many predictors/Xs/features we have to predict y
b_size = 250 # Number of timeseries samples in each batch
generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=n_input, batch_size=b_size)# 80 good

print(generator[0][0].shape)

opt= tf.optimizers.SGD(lr=0.8, decay=1e-6)#0.1 good #0.06   0.8 ++
activation='relu'
model = Sequential()

model.add(CuDNNLSTM(800, input_shape=(n_input, n_features)))

model.add(Dense(80,activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(800,activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(100,activation = 'relu'))
model.add(Dense(1,activation = 'sigmoid'))



model.compile(optimizer= opt , loss='mse',metrics=['accuracy'])
model.summary()

model.fit_generator(generator,epochs=105)

loss_per_epoch = model.history.history['loss']
plt.plot(range(len(loss_per_epoch)),loss_per_epoch);
font1 = {'family':'serif','color':'blue','size':20}
font2 = {'family':'serif','color':'darkred','size':15}

plt.xlabel("Epoch", fontdict = font1)
plt.ylabel("Loss", fontdict = font2)
plt.title("Loss per Epoch (CBW)", fontdict = font2)
plt.savefig('/content/loss per epoch graph(CBW) .jpg')

X_test = test.drop(y_col,axis=1).copy()
scaled_X_test = Xscaler.transform(X_test)
test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=n_input, batch_size=b_size)
print(test_generator[0][0].shape)
print(X_test)

y_pred_scaled = model.predict(test_generator)
y_pred = Yscaler.inverse_transform(y_pred_scaled)
results = pd.DataFrame({'y_true':test[y_col].values[n_input:],'y_pred':y_pred.ravel()})
print(results)
results.to_csv('/content/ x1.csv')

plt.plot(y_pred)
plt.plot(test[y_col].values[n_input:])
t = np.arange(0.0,0.2, 0.1)
#plt.ylim(0,0.2)

predic1 = pd.read_excel('/content/FINAL2.xlsx','WELL-B') # read data
predic1= predic1.iloc[:,1:]
predic1.head()

predic2 = pd.DataFrame()
for i in p1:
  predic2[i] = predic1[i]
print(predic2)

scaled_predic = Xscaler.transform(predic2)
test_generator = TimeseriesGenerator(scaled_predic, np.zeros(len(predic2)), length=n_input, batch_size=b_size)
print(test_generator[0][0].shape)

y_pred_scaled = model.predict(test_generator)
y_pred = Yscaler.inverse_transform(y_pred_scaled)
results = pd.DataFrame({'CBW':y_pred.ravel()})
print(results)

results.to_csv('/content/ CBw(b).csv')





